"""
SmartPromo AI Model - Mod√®le d'Intelligence Artificielle pour le Calcul Optimal des Promotions
=========================================================================================

Ce mod√®le calcule le pourcentage de promotion optimal pour chaque article en se basant sur :
- Rotation des stocks
- √âlasticit√© prix/demande
- Historique des ventes
- Historique des promotions

Et pr√©dit l'impact sur le revenu et le volume des ventes.
"""

import pyodbc
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
import logging
from typing import Dict, List, Tuple, Optional
import json
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import joblib
import os

warnings.filterwarnings('ignore')

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SmartPromoAIModel:
    """
    Mod√®le d'IA pour calculer les pourcentages de promotion optimaux
    """
    
    def __init__(self, connection_string: str):
        """
        Initialise le mod√®le avec la cha√Æne de connexion √† la base de donn√©es
        
        Args:
            connection_string (str): Cha√Æne de connexion SQL Server
        """
        self.connection_string = connection_string
        self.connection = None
        
        # Poids pour la formule de calcul (pond√©ration selon l'importance)
        self.weights = {
            'stock_rotation': 0.35,      # 35% - Rotation des stocks
            'price_elasticity': 0.25,    # 25% - √âlasticit√© prix/demande
            'sales_history': 0.25,       # 25% - Historique des ventes
            'promotion_history': 0.15    # 15% - Historique des promotions
        }
        
        # Param√®tres de seuils
        self.thresholds = {
            'min_promotion': 5,     # Promotion minimale de 5%
            'max_promotion': 50,    # Promotion maximale de 50%
            'stock_critical': 10,   # Seuil critique de stock
            'stock_excess': 100     # Seuil de surstock
        }
        
        # Mod√®les d'IA
        self.models = {
            'random_forest': RandomForestRegressor(n_estimators=100, random_state=42),
            'gradient_boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),
            'linear_regression': LinearRegression()
        }
        self.best_model = None
        self.scaler = StandardScaler()
        self.is_trained = False
        self.model_metrics = {}
        
    def connect_database(self) -> bool:
        """
        √âtablit la connexion √† la base de donn√©es avec gestion robuste des pilotes ODBC
        
        Returns:
            bool: True si connexion r√©ussie, False sinon
        """
        try:
            # Liste des cha√Ænes de connexion √† essayer (dans l'ordre de pr√©f√©rence)
            connection_strings = [
                # Pilote ODBC Driver 17 (fonctionne selon le diagnostic)
                "DRIVER={ODBC Driver 17 for SQL Server};Server=DESKTOP-S22JEMV\\SQLEXPRESS;Database=SmartPromoDb_v2026_Fresh;Trusted_Connection=yes;",
                
                # Pilote SQL Server standard (fonctionne aussi)
                "DRIVER={SQL Server};Server=DESKTOP-S22JEMV\\SQLEXPRESS;Database=SmartPromoDb_v2026_Fresh;Trusted_Connection=yes;",
                
                # Pilote ODBC Driver 18 avec certificat
                "DRIVER={ODBC Driver 18 for SQL Server};Server=DESKTOP-S22JEMV\\SQLEXPRESS;Database=SmartPromoDb_v2026_Fresh;Trusted_Connection=yes;TrustServerCertificate=yes;",
                
                # Cha√Æne originale
                self.connection_string,
                
                # SQL Server Native Client
                "DRIVER={SQL Server Native Client 11.0};Server=DESKTOP-S22JEMV\\SQLEXPRESS;Database=SmartPromoDb_v2026_Fresh;Trusted_Connection=yes;"
            ]
            
            for i, conn_str in enumerate(connection_strings, 1):
                try:
                    logger.info(f"Tentative de connexion {i}/5...")
                    self.connection = pyodbc.connect(conn_str, timeout=10)
                    logger.info("‚úÖ Connexion √† la base de donn√©es √©tablie avec succ√®s")
                    return True
                except Exception as conn_error:
                    logger.warning(f"‚ùå Tentative {i} √©chou√©e: {str(conn_error)[:100]}...")
                    continue
            
            logger.error("üö´ Toutes les tentatives de connexion ont √©chou√©")
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©rale de connexion √† la base de donn√©es: {e}")
            return False
    
    def disconnect_database(self):
        """Ferme la connexion √† la base de donn√©es"""
        if self.connection:
            self.connection.close()
            logger.info("Connexion √† la base de donn√©es ferm√©e")
    
    def extract_articles_by_category(self, category_id: int) -> pd.DataFrame:
        """
        Extrait les articles d'une cat√©gorie sp√©cifique
        
        Args:
            category_id (int): ID de la cat√©gorie
            
        Returns:
            pd.DataFrame: DataFrame contenant les articles
        """
        query = """
        SELECT 
            a.Id as ArticleId,
            a.Libelle as ArticleName,
            a.Prix_Vente_TND as Price,
            ISNULL(s.QuantitePhysique, 0) as CurrentStock,
            ISNULL(s.StockMin, 5) as MinStockThreshold,
            a.IdCategorie as CategoryId,
            c.Nom as CategoryName,
            a.CodeArticle
        FROM Articles a
        LEFT JOIN Categories c ON a.IdCategorie = c.IdCategorie
        LEFT JOIN Stocks s ON a.Id = s.ArticleId
        WHERE a.IdCategorie = ?
        AND a.Prix_Vente_TND > 0
        """
        
        try:
            df = pd.read_sql(query, self.connection, params=[str(category_id)])
            logger.info(f"Extraction de {len(df)} articles pour la cat√©gorie {category_id}")
            return df
        except Exception as e:
            logger.error(f"Erreur lors de l'extraction des articles: {e}")
            return pd.DataFrame()
    
    def get_sales_history(self, article_id: int, days: int = 90) -> pd.DataFrame:
        """
        R√©cup√®re l'historique des ventes d'un article
        
        Args:
            article_id (int): ID de l'article
            days (int): Nombre de jours d'historique
            
        Returns:
            pd.DataFrame: Historique des ventes
        """
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        query = """
        SELECT 
            v.Date as SaleDate,
            v.QuantiteFacturee as QuantitySold,
            v.Prix_Vente_TND as SalePrice,
            s.ArticleId,
            s.QuantitePhysique as CurrentStock,
            ISNULL(s.QuantitePhysique, 0) as QuantityInjected
        FROM Ventes v
        JOIN Stocks s ON v.StockId = s.Id
        WHERE s.ArticleId = ?
        AND v.Date >= ?
        AND v.Date <= ?
        ORDER BY v.Date
        """
        
        try:
            df = pd.read_sql(query, self.connection, 
                           params=[article_id, start_date, end_date])
            return df
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration de l'historique des ventes: {e}")
            return pd.DataFrame()
    
    def get_promotion_history(self, article_id: int, days: int = 180) -> pd.DataFrame:
        """
        R√©cup√®re l'historique des promotions d'un article avec prix avant/apr√®s
        
        Args:
            article_id (int): ID de l'article
            days (int): Nombre de jours d'historique
            
        Returns:
            pd.DataFrame: Historique des promotions avec prix
        """
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        query = """
        SELECT 
            p.DateDebut as StartDate,
            p.DateFin as EndDate,
            p.TauxReduction as DiscountPercentage,
            p.CodeArticle,
            a.Id as ArticleId,
            a.Prix_Vente_TND as PriceBeforePromo,
            (a.Prix_Vente_TND * (1 - p.TauxReduction / 100.0)) as PriceAfterPromo,
            -- Calcul des ventes pendant cette promotion
            (SELECT SUM(v.QuantiteFacturee)
             FROM Ventes v
             JOIN Stocks s ON v.StockId = s.Id
             WHERE s.ArticleId = a.Id
             AND v.Date BETWEEN p.DateDebut AND p.DateFin
            ) as SalesDuringPromo
        FROM Promotions p
        JOIN Articles a ON p.CodeArticle = a.CodeArticle
        WHERE a.Id = ?
        AND p.DateDebut >= ?
        AND p.DateFin <= ?
        ORDER BY p.DateDebut
        """
        
        try:
            df = pd.read_sql(query, self.connection, 
                           params=[article_id, start_date, end_date])
            return df
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration de l'historique des promotions: {e}")
            return pd.DataFrame()
    
    def calculate_stock_rotation_score(self, article_row: pd.Series, sales_history: pd.DataFrame) -> float:
        """
        Calcule le score de rotation des stocks selon la formule correcte:
        Rotation = Quantit√© vendue / Quantit√© inject√©e
        
        Args:
            article_row (pd.Series): Donn√©es de l'article
            sales_history (pd.DataFrame): Historique des ventes
            
        Returns:
            float: Score de rotation (0-1)
        """
        current_stock = article_row['CurrentStock']
        min_threshold = article_row['MinStockThreshold']
        
        if sales_history.empty:
            return 0.5  # Score neutre si pas d'historique
        
        # Calcul de la rotation correcte : Quantit√© vendue / Quantit√© inject√©e
        total_sales = sales_history['QuantitySold'].sum()
        total_injected = sales_history['QuantityInjected'].sum()
        
        if total_injected == 0:
            return 0.5  # Score neutre si pas d'injection
        
        # Calcul du taux de rotation r√©el
        rotation_rate = total_sales / total_injected
        
        if current_stock == 0:
            return 1.0  # Stock critique - promotion maximale
        
        # Normalisation du score bas√© sur la rotation
        if current_stock <= min_threshold:
            # Stock faible mais on regarde la rotation
            return min(0.8, rotation_rate)  # Max 0.8 pour stock faible
        elif current_stock >= self.thresholds['stock_excess']:
            return 0.9  # Surstock - promotion √©lev√©e
        else:
            # Score proportionnel √† la rotation
            # Une rotation √©lev√©e (>1) indique un bon √©coulement
            # Une rotation faible (<0.5) indique des difficult√©s de vente
            if rotation_rate > 1.0:
                return 0.3  # Bon √©coulement - promotion faible
            elif rotation_rate > 0.7:
                return 0.5  # √âcoulement moyen
            elif rotation_rate > 0.4:
                return 0.7  # √âcoulement lent - promotion mod√©r√©e
            else:
                return 0.9  # √âcoulement tr√®s lent - promotion forte
    
    def calculate_price_elasticity_score(self, article_row: pd.Series, sales_history: pd.DataFrame, promotion_history: pd.DataFrame = None) -> float:
        """
        Calcule le score d'√©lasticit√© prix/demande en utilisant les prix avant et apr√®s promotion
        
        Args:
            article_row (pd.Series): Donn√©es de l'article
            sales_history (pd.DataFrame): Historique des ventes
            promotion_history (pd.DataFrame): Historique des promotions avec prix avant/apr√®s
            
        Returns:
            float: Score d'√©lasticit√© (0-1)
        """
        # Si on a l'historique des promotions avec les prix, on l'utilise
        if promotion_history is not None and not promotion_history.empty and len(promotion_history) >= 2:
            try:
                # Calcul de l'√©lasticit√© bas√©e sur les promotions pass√©es
                elasticity_scores = []
                
                for _, promo in promotion_history.iterrows():
                    price_before = promo['PriceBeforePromo']
                    price_after = promo['PriceAfterPromo']
                    sales_during = promo.get('SalesDuringPromo', 0)
                    
                    if price_before > 0 and price_after > 0 and sales_during > 0:
                        # Calcul du changement de prix en pourcentage
                        price_change_pct = (price_after - price_before) / price_before
                        
                        # Estimation des ventes avant promotion (bas√©e sur historique)
                        if not sales_history.empty:
                            avg_sales_before = sales_history['QuantitySold'].mean()
                        else:
                            avg_sales_before = sales_during * 0.7  # Estimation conservatrice
                        
                        if avg_sales_before > 0:
                            # Calcul du changement de quantit√© en pourcentage
                            quantity_change_pct = (sales_during - avg_sales_before) / avg_sales_before
                            
                            # Calcul de l'√©lasticit√©: variation demande / variation prix
                            if price_change_pct != 0:
                                elasticity = abs(quantity_change_pct / price_change_pct)
                                elasticity_scores.append(elasticity)
                
                if elasticity_scores:
                    # Moyenne des √©lasticit√©s calcul√©es
                    avg_elasticity = np.mean(elasticity_scores)
                    
                    # Normalisation du score d'√©lasticit√©
                    # √âlasticit√© √©lev√©e (> 2) = tr√®s sensible au prix = score √©lev√© pour promotion
                    # √âlasticit√© faible (< 0.5) = peu sensible au prix = score faible pour promotion
                    if avg_elasticity > 2.0:
                        return 0.9  # Tr√®s √©lastique - promotion tr√®s efficace
                    elif avg_elasticity > 1.5:
                        return 0.8  # Assez √©lastique - promotion efficace
                    elif avg_elasticity > 1.0:
                        return 0.6  # Moyennement √©lastique
                    elif avg_elasticity > 0.5:
                        return 0.4  # Peu √©lastique
                    else:
                        return 0.2  # Tr√®s peu √©lastique - promotion peu efficace
                        
            except Exception as e:
                logger.warning(f"Erreur dans le calcul d'√©lasticit√© avec promotions: {e}")
        
        # M√©thode de fallback bas√©e sur l'historique des ventes (m√©thode originale)
        if sales_history.empty or len(sales_history) < 10:
            return 0.5  # Score neutre si donn√©es insuffisantes
        
        current_price = article_row['Price']
        
        # Calcul de la corr√©lation prix/quantit√© dans l'historique des ventes
        price_changes = sales_history['SalePrice'].pct_change().dropna()
        quantity_changes = sales_history['QuantitySold'].pct_change().dropna()
        
        if len(price_changes) < 5 or len(quantity_changes) < 5:
            return 0.5
        
        # √âlasticit√© = variation relative de la demande / variation relative du prix
        correlation = np.corrcoef(price_changes, quantity_changes)[0, 1]
        
        if np.isnan(correlation):
            return 0.5
        
        # Conversion en score (plus la corr√©lation est n√©gative, plus l'√©lasticit√© est forte)
        elasticity_score = min(0.9, max(0.1, (1 - correlation) / 2))
        
        return elasticity_score
    
    def calculate_sales_history_score(self, sales_history: pd.DataFrame) -> float:
        """
        Calcule le score bas√© sur l'historique des ventes
        
        Args:
            sales_history (pd.DataFrame): Historique des ventes
            
        Returns:
            float: Score des ventes (0-1)
        """
        if sales_history.empty:
            return 0.3  # Score faible si pas d'historique
        
        # Tendance des ventes (croissante/d√©croissante)
        sales_by_week = sales_history.groupby(
            sales_history['SaleDate'].dt.isocalendar().week
        )['QuantitySold'].sum()
        
        if len(sales_by_week) < 2:
            return 0.5
        
        # Calcul de la tendance
        trend = np.polyfit(range(len(sales_by_week)), sales_by_week.values, 1)[0]
        
        # Score bas√© sur la tendance
        if trend > 0:  # Tendance croissante - promotion mod√©r√©e
            return 0.3
        elif trend < -0.5:  # Tendance tr√®s d√©croissante - promotion forte
            return 0.8
        else:  # Tendance stable ou l√©g√®rement d√©croissante
            return 0.6
    
    def calculate_promotion_history_score(self, promotion_history: pd.DataFrame) -> float:
        """
        Calcule le score bas√© sur l'historique des promotions
        
        Args:
            promotion_history (pd.DataFrame): Historique des promotions
            
        Returns:
            float: Score des promotions (0-1)
        """
        if promotion_history.empty:
            return 0.7  # Score √©lev√© si jamais promu
        
        # Fr√©quence des promotions
        recent_promotions = promotion_history[
            promotion_history['EndDate'] >= datetime.now() - timedelta(days=60)
        ]
        
        if len(recent_promotions) > 2:
            return 0.2  # Trop de promotions r√©centes - r√©duire
        elif len(recent_promotions) == 0:
            return 0.8  # Pas de promotion r√©cente - augmenter
        else:
            return 0.5  # √âquilibr√©
    
    def extract_training_data(self) -> pd.DataFrame:
        """
        Extrait les donn√©es d'entra√Ænement √† partir de l'historique des promotions et ventes
        
        Returns:
            pd.DataFrame: Donn√©es d'entra√Ænement avec features et target
        """
        query = """
        SELECT 
            a.Id as ArticleId,
            a.Prix_Vente_TND as Price,
            a.IdCategorie as CategoryId,
            ISNULL(s.QuantitePhysique, 0) as CurrentStock,
            ISNULL(s.StockMin, 5) as MinStockThreshold,
            ISNULL(s.QuantitePhysique, 0) as QuantityInjected,
            p.TauxReduction as PromotionPercentage,
            p.DateDebut,
            p.DateFin,
            -- Calcul des ventes avant promotion (30 jours avant)
            (SELECT SUM(v1.QuantiteFacturee) 
             FROM Ventes v1 
             JOIN Stocks s1 ON v1.StockId = s1.Id 
             WHERE s1.ArticleId = a.Id 
             AND v1.Date BETWEEN DATEADD(day, -60, p.DateDebut) AND DATEADD(day, -30, p.DateDebut)
            ) as SalesBeforePromo,
            -- Calcul des ventes pendant promotion
            (SELECT SUM(v2.QuantiteFacturee) 
             FROM Ventes v2 
             JOIN Stocks s2 ON v2.StockId = s2.Id 
             WHERE s2.ArticleId = a.Id 
             AND v2.Date BETWEEN p.DateDebut AND p.DateFin
            ) as SalesDuringPromo,
            -- Calcul des revenus avant promotion
            (SELECT SUM(v3.QuantiteFacturee * v3.Prix_Vente_TND) 
             FROM Ventes v3 
             JOIN Stocks s3 ON v3.StockId = s3.Id 
             WHERE s3.ArticleId = a.Id 
             AND v3.Date BETWEEN DATEADD(day, -60, p.DateDebut) AND DATEADD(day, -30, p.DateDebut)
            ) as RevenueBeforePromo,
            -- Calcul des revenus pendant promotion
            (SELECT SUM(v4.QuantiteFacturee * v4.Prix_Vente_TND) 
             FROM Ventes v4 
             JOIN Stocks s4 ON v4.StockId = s4.Id 
             WHERE s4.ArticleId = a.Id 
             AND v4.Date BETWEEN p.DateDebut AND p.DateFin
            ) as RevenueDuringPromo
        FROM Articles a
        LEFT JOIN Stocks s ON a.Id = s.ArticleId
        JOIN Promotions p ON a.CodeArticle = p.CodeArticle
        WHERE p.DateFin < GETDATE()
        AND a.Prix_Vente_TND > 0
        """
        
        try:
            df = pd.read_sql(query, self.connection)
            
            # Nettoyage et calcul des features
            df = df.dropna(subset=['SalesBeforePromo', 'SalesDuringPromo'])
            
            # Calcul de la rotation
            df['RotationRate'] = df['SalesBeforePromo'] / df['QuantityInjected'].replace(0, 1)
            
            # Calcul de l'efficacit√© de la promotion (target)
            df['PromotionEffectiveness'] = (df['SalesDuringPromo'] / (df['SalesBeforePromo'].replace(0, 1))) - 1
            
            # Calcul du changement de revenus
            df['RevenueChange'] = (df['RevenueDuringPromo'] / df['RevenueBeforePromo'].replace(0, 1)) - 1
            
            # Seuil de stock
            df['StockLevel'] = df['CurrentStock'] / df['MinStockThreshold'].replace(0, 1)
            
            # Niveau de prix (compar√© √† la moyenne de la cat√©gorie)
            avg_price_by_category = df.groupby('CategoryId')['Price'].mean()
            df['PriceLevel'] = df.apply(lambda row: row['Price'] / avg_price_by_category[row['CategoryId']], axis=1)
            
            logger.info(f"Donn√©es d'entra√Ænement extraites: {len(df)} √©chantillons")
            return df
            
        except Exception as e:
            logger.error(f"Erreur lors de l'extraction des donn√©es d'entra√Ænement: {e}")
            return pd.DataFrame()
    
    def generate_simulated_training_data(self, n_samples: int = 200) -> pd.DataFrame:
        """
        G√©n√®re des donn√©es d'entra√Ænement simul√©es pour l'IA
        
        Args:
            n_samples (int): Nombre d'√©chantillons √† g√©n√©rer
            
        Returns:
            pd.DataFrame: Donn√©es simul√©es pour l'entra√Ænement
        """
        np.random.seed(42)  # Pour la reproductibilit√©
        
        # Simulation de diff√©rents types d'articles et promotions
        data = {
            'ArticleId': range(1, n_samples + 1),
            'Price': np.random.uniform(20, 300, n_samples),
            'CategoryId': np.random.choice([1, 2, 3, 4, 5], n_samples),
            'CurrentStock': np.random.randint(0, 150, n_samples),
            'MinStockThreshold': np.random.randint(5, 25, n_samples),
            'QuantityInjected': np.random.randint(50, 800, n_samples),
            'PromotionPercentage': np.random.uniform(5, 45, n_samples),
        }
        
        # Calculs des ventes bas√©s sur des facteurs r√©alistes
        base_sales = np.random.randint(10, 80, n_samples)
        promotion_effect = 1 + (data['PromotionPercentage'] / 100) * np.random.uniform(1.5, 3.0, n_samples)
        
        # Ventes avant promotion (baseline)
        data['SalesBeforePromo'] = base_sales
        
        # Ventes pendant promotion (augment√©es selon l'effet promotion)
        data['SalesDuringPromo'] = np.round(base_sales * promotion_effect).astype(int)
        
        # Simulation des revenus
        base_revenue = data['Price'] * np.array(data['SalesBeforePromo'])
        promo_price = np.array(data['Price']) * (1 - np.array(data['PromotionPercentage']) / 100)
        promo_revenue = promo_price * data['SalesDuringPromo']
        
        data['RevenueBeforePromo'] = base_revenue
        data['RevenueDuringPromo'] = promo_revenue
        
        df = pd.DataFrame(data)
        
        # Calcul des features d√©riv√©es (comme dans la m√©thode r√©elle)
        df['RotationRate'] = df['SalesBeforePromo'] / df['QuantityInjected'].replace(0, 1)
        df['PromotionEffectiveness'] = (df['SalesDuringPromo'] / df['SalesBeforePromo'].replace(0, 1)) - 1
        df['RevenueChange'] = (df['RevenueDuringPromo'] / df['RevenueBeforePromo'].replace(0, 1)) - 1
        df['StockLevel'] = df['CurrentStock'] / df['MinStockThreshold'].replace(0, 1)
        
        # Niveau de prix par cat√©gorie
        avg_price_by_category = df.groupby('CategoryId')['Price'].mean()
        df['PriceLevel'] = df.apply(lambda row: row['Price'] / avg_price_by_category[row['CategoryId']], axis=1)
        
        logger.info(f"‚úÖ Donn√©es simul√©es g√©n√©r√©es: {len(df)} √©chantillons")
        return df
    
    def prepare_features(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
        """
        Pr√©pare les features et target pour l'entra√Ænement
        
        Args:
            df (pd.DataFrame): Donn√©es brutes
            
        Returns:
            Tuple[pd.DataFrame, pd.Series]: Features (X) et target (y)
        """
        # S√©lection des features
        feature_columns = [
            'Price', 'CurrentStock', 'MinStockThreshold', 'QuantityInjected',
            'RotationRate', 'StockLevel', 'PriceLevel', 'CategoryId'
        ]
        
        X = df[feature_columns].copy()
        
        # Target: combinaison d'efficacit√© ventes et revenus
        # Plus le score est √©lev√©, plus la promotion devrait √™tre importante
        y = (df['PromotionEffectiveness'] * 0.6 + df['RevenueChange'] * 0.4) * 100
        
        # Nettoyage des valeurs aberrantes
        X = X.fillna(X.median())
        y = y.fillna(y.median())
        
        # Limitation des valeurs extr√™mes du target
        y = np.clip(y, -50, 200)  # Entre -50% et +200% d'efficacit√©
        
        return X, y
    
    def train_models(self, use_simulation: bool = False) -> bool:
        """
        Entra√Æne les mod√®les d'IA avec les donn√©es historiques ou simul√©es
        
        Args:
            use_simulation (bool): Utiliser des donn√©es simul√©es si True
        
        Returns:
            bool: True si l'entra√Ænement a r√©ussi
        """
        logger.info("ü§ñ D√©but de l'entra√Ænement des mod√®les d'IA...")
        
        training_data = pd.DataFrame()
        
        if use_simulation:
            logger.info("üìä Utilisation de donn√©es simul√©es pour l'entra√Ænement...")
            training_data = self.generate_simulated_training_data()
        else:
            if not self.connect_database():
                logger.warning("‚ùå Connexion √©chou√©e, basculement vers donn√©es simul√©es...")
                training_data = self.generate_simulated_training_data()
                use_simulation = True
            else:
                try:
                    # Extraction des donn√©es d'entra√Ænement r√©elles
                    training_data = self.extract_training_data()
                finally:
                    self.disconnect_database()
        
        if training_data.empty or len(training_data) < 50:
            if not use_simulation:
                logger.warning("Donn√©es r√©elles insuffisantes, g√©n√©ration de donn√©es simul√©es...")
                training_data = self.generate_simulated_training_data()
            else:
                logger.error("Impossible de g√©n√©rer suffisamment de donn√©es d'entra√Ænement")
                return False
        
        try:
            # Pr√©paration des features
            X, y = self.prepare_features(training_data)
            
            # Division train/test
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )
            
            # Normalisation
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)
            
            best_score = -np.inf
            
            # Entra√Ænement de chaque mod√®le
            for name, model in self.models.items():
                logger.info(f"Entra√Ænement du mod√®le: {name}")
                
                # Entra√Ænement
                if name == 'linear_regression':
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)
                else:
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                
                # √âvaluation
                mse = mean_squared_error(y_test, y_pred)
                r2 = r2_score(y_test, y_pred)
                mae = mean_absolute_error(y_test, y_pred)
                
                # Stockage des m√©triques
                self.model_metrics[name] = {
                    'mse': mse,
                    'r2': r2,
                    'mae': mae,
                    'rmse': np.sqrt(mse)
                }
                
                logger.info(f"  {name}: R¬≤ = {r2:.3f}, RMSE = {np.sqrt(mse):.3f}")
                
                # S√©lection du meilleur mod√®le
                if r2 > best_score:
                    best_score = r2
                    self.best_model = model
                    self.best_model_name = name
            
            self.is_trained = True
            data_source = "simul√©es" if use_simulation or not self.connection else "r√©elles"
            logger.info(f"‚úÖ Entra√Ænement termin√© avec donn√©es {data_source}. Meilleur mod√®le: {self.best_model_name} (R¬≤ = {best_score:.3f})")
            
            # Sauvegarde du mod√®le
            self.save_model()
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'entra√Ænement: {e}")
            return False
    
    def save_model(self):
        """Sauvegarde le mod√®le entra√Æn√©"""
        try:
            model_dir = "trained_models"
            os.makedirs(model_dir, exist_ok=True)
            
            # Sauvegarde du meilleur mod√®le
            joblib.dump(self.best_model, f"{model_dir}/best_model.pkl")
            joblib.dump(self.scaler, f"{model_dir}/scaler.pkl")
            
            # Sauvegarde des m√©triques
            with open(f"{model_dir}/metrics.json", 'w') as f:
                json.dump(self.model_metrics, f, indent=2)
                
            logger.info(f"üìÅ Mod√®le sauvegard√© dans {model_dir}/")
            
        except Exception as e:
            logger.error(f"Erreur lors de la sauvegarde: {e}")
    
    def load_model(self) -> bool:
        """Charge un mod√®le pr√©-entra√Æn√©"""
        try:
            model_dir = "trained_models"
            
            if not os.path.exists(f"{model_dir}/best_model.pkl"):
                return False
            
            self.best_model = joblib.load(f"{model_dir}/best_model.pkl")
            self.scaler = joblib.load(f"{model_dir}/scaler.pkl")
            
            with open(f"{model_dir}/metrics.json", 'r') as f:
                self.model_metrics = json.load(f)
            
            self.is_trained = True
            logger.info("‚úÖ Mod√®le pr√©-entra√Æn√© charg√© avec succ√®s")
            return True
            
        except Exception as e:
            logger.error(f"Erreur lors du chargement: {e}")
            return False
    
    def calculate_optimal_promotion_percentage(self, article_row: pd.Series) -> Dict:
        """
        Calcule le pourcentage de promotion optimal pour un article en utilisant l'IA
        
        Args:
            article_row (pd.Series): Donn√©es de l'article
            
        Returns:
            Dict: R√©sultats du calcul
        """
        article_id = article_row['ArticleId']
        
        # R√©cup√©ration des historiques
        sales_history = self.get_sales_history(article_id)
        promotion_history = self.get_promotion_history(article_id)
        
        # Calcul des scores individuels (pour compatibilit√© et transparence)
        stock_score = self.calculate_stock_rotation_score(article_row, sales_history)
        elasticity_score = self.calculate_price_elasticity_score(article_row, sales_history, promotion_history)
        sales_score = self.calculate_sales_history_score(sales_history)
        promotion_score = self.calculate_promotion_history_score(promotion_history)
        
        # Calcul du score final pond√©r√© (m√©thode classique)
        final_score = (
            stock_score * self.weights['stock_rotation'] +
            elasticity_score * self.weights['price_elasticity'] +
            sales_score * self.weights['sales_history'] +
            promotion_score * self.weights['promotion_history']
        )
        
        # Promotion par m√©thode classique
        classic_promotion_percentage = (
            self.thresholds['min_promotion'] + 
            (self.thresholds['max_promotion'] - self.thresholds['min_promotion']) * final_score
        )
        
        # Pr√©diction par IA si le mod√®le est entra√Æn√©
        ai_promotion_percentage = classic_promotion_percentage
        prediction_method = "classic"
        
        if self.is_trained and self.best_model is not None:
            try:
                # Pr√©paration des features pour l'IA
                total_injected = sales_history['QuantityInjected'].sum() if not sales_history.empty else article_row['CurrentStock']
                rotation_rate = sales_history['QuantitySold'].sum() / total_injected if total_injected > 0 else 0
                stock_level = article_row['CurrentStock'] / article_row['MinStockThreshold'] if article_row['MinStockThreshold'] > 0 else 1
                
                # Calcul du prix relatif (approximation)
                price_level = 1.0  # Valeur par d√©faut si pas de donn√©es de cat√©gorie
                
                features = pd.DataFrame({
                    'Price': [article_row['Price']],
                    'CurrentStock': [article_row['CurrentStock']],
                    'MinStockThreshold': [article_row['MinStockThreshold']],
                    'QuantityInjected': [total_injected],
                    'RotationRate': [rotation_rate],
                    'StockLevel': [stock_level],
                    'PriceLevel': [price_level],
                    'CategoryId': [article_row.get('CategoryId', 1)]
                })
                
                # Pr√©diction
                if hasattr(self, 'best_model_name') and self.best_model_name == 'linear_regression':
                    features_scaled = self.scaler.transform(features)
                    ai_effectiveness = self.best_model.predict(features_scaled)[0]
                else:
                    ai_effectiveness = self.best_model.predict(features)[0]
                
                # Conversion de l'efficacit√© pr√©dite en pourcentage de promotion
                # Plus l'efficacit√© pr√©dite est faible, plus la promotion doit √™tre √©lev√©e
                if ai_effectiveness < 0:  # Efficacit√© n√©gative = besoin de promotion
                    ai_promotion_percentage = min(self.thresholds['max_promotion'], 
                                                abs(ai_effectiveness) * 0.5 + self.thresholds['min_promotion'])
                else:  # Efficacit√© positive = promotion mod√©r√©e
                    ai_promotion_percentage = max(self.thresholds['min_promotion'],
                                                self.thresholds['max_promotion'] - (ai_effectiveness * 0.3))
                
                prediction_method = "ai"
                
            except Exception as e:
                logger.warning(f"Erreur lors de la pr√©diction IA: {e}, utilisation m√©thode classique")
                ai_promotion_percentage = classic_promotion_percentage
                prediction_method = "classic_fallback"
        
        # Arrondi √† l'entier le plus proche
        final_promotion_percentage = round(ai_promotion_percentage)
        
        # Cr√©ation des donn√©es de base pour l'impact
        basic_result = {
            'article_id': article_id,
            'article_name': article_row['ArticleName'],
            'current_price': article_row['Price'],
            'current_stock': article_row['CurrentStock'],
            'stock_score': round(stock_score, 3),
            'elasticity_score': round(elasticity_score, 3),
            'sales_score': round(sales_score, 3),
            'promotion_score': round(promotion_score, 3),
            'final_score': round(final_score, 3),
            'classic_promotion_percentage': round(classic_promotion_percentage),
            'optimal_promotion_percentage': final_promotion_percentage,
            'prediction_method': prediction_method,
            'discounted_price': round(article_row['Price'] * (1 - final_promotion_percentage/100), 2)
        }
        
        # Calcul de l'impact pr√©vu
        impact_data = self.predict_impact(basic_result, sales_history)
        
        # Fusion des r√©sultats
        complete_result = {**basic_result, **impact_data}
        
        return complete_result
    
    def predict_impact(self, article_data: Dict, sales_history: pd.DataFrame) -> Dict:
        """
        Pr√©dit l'impact de la promotion sur le revenu et le volume des ventes
        
        Args:
            article_data (Dict): Donn√©es de l'article avec promotion
            sales_history (pd.DataFrame): Historique des ventes
            
        Returns:
            Dict: Pr√©dictions d'impact
        """
        promotion_percentage = article_data['optimal_promotion_percentage']
        current_price = article_data['current_price']
        discounted_price = article_data['discounted_price']
        
        # Calcul des m√©triques de base
        if sales_history.empty:
            avg_daily_sales = 1
            avg_daily_revenue = current_price
        else:
            avg_daily_sales = sales_history['QuantitySold'].mean()
            avg_daily_revenue = (sales_history['QuantitySold'] * sales_history['SalePrice']).mean()
        
        # Estimation de l'augmentation des ventes bas√©e sur l'√©lasticit√©
        # Plus la promotion est importante, plus l'augmentation est significative
        sales_increase_factor = 1 + (promotion_percentage / 100) * 2  # Facteur d'augmentation
        
        predicted_daily_sales = avg_daily_sales * sales_increase_factor
        predicted_daily_revenue = predicted_daily_sales * discounted_price
        
        # Calcul de l'impact sur 30 jours
        monthly_current_revenue = avg_daily_revenue * 30
        monthly_predicted_revenue = predicted_daily_revenue * 30
        monthly_current_sales = avg_daily_sales * 30
        monthly_predicted_sales = predicted_daily_sales * 30
        
        revenue_change = monthly_predicted_revenue - monthly_current_revenue
        revenue_change_percentage = (revenue_change / monthly_current_revenue) * 100 if monthly_current_revenue > 0 else 0
        
        sales_change = monthly_predicted_sales - monthly_current_sales
        sales_change_percentage = (sales_change / monthly_current_sales) * 100 if monthly_current_sales > 0 else 0
        
        return {
            'current_monthly_sales_volume': round(monthly_current_sales, 2),
            'predicted_monthly_sales_volume': round(monthly_predicted_sales, 2),
            'sales_volume_change': round(sales_change, 2),
            'sales_volume_change_percentage': round(sales_change_percentage, 2),
            'current_monthly_revenue': round(monthly_current_revenue, 2),
            'predicted_monthly_revenue': round(monthly_predicted_revenue, 2),
            'revenue_change': round(revenue_change, 2),
            'revenue_change_percentage': round(revenue_change_percentage, 2),
            'recommendation': self.get_recommendation(article_data, revenue_change_percentage, sales_change_percentage)
        }
    
    def get_recommendation(self, article_data: Dict, revenue_change: float, sales_change: float) -> str:
        """
        G√©n√®re une recommandation bas√©e sur les pr√©dictions
        
        Args:
            article_data (Dict): Donn√©es de l'article
            revenue_change (float): Changement de revenu pr√©dit
            sales_change (float): Changement de volume pr√©dit
            
        Returns:
            str: Recommandation
        """
        stock = article_data['current_stock']
        promotion = article_data['optimal_promotion_percentage']
        
        if stock <= self.thresholds['stock_critical']:
            return f"‚ö†Ô∏è STOCK CRITIQUE: √âviter la promotion ({promotion}%) pour √©viter la rupture de stock"
        elif stock >= self.thresholds['stock_excess']:
            return f"üìà SURSTOCK: Promotion recommand√©e ({promotion}%) pour √©couler le stock"
        elif revenue_change > 0 and sales_change > 20:
            return f"‚úÖ PROMOTION RENTABLE: Augmentation pr√©vue du revenu ({revenue_change:.1f}%) et des ventes ({sales_change:.1f}%)"
        elif revenue_change < -10:
            return f"‚ùå RISQUE: La promotion pourrait r√©duire significativement le revenu ({revenue_change:.1f}%)"
        else:
            return f"‚öñÔ∏è NEUTRE: Impact mod√©r√© pr√©vu. Promotion de {promotion}% acceptable"
    
    def analyze_category(self, category_id: int) -> List[Dict]:
        """
        Analyse compl√®te d'une cat√©gorie d'articles
        
        Args:
            category_id (int): ID de la cat√©gorie
            
        Returns:
            List[Dict]: Analyses compl√®tes de tous les articles
        """
        if not self.connect_database():
            return []
        
        try:
            # Extraction des articles
            articles_df = self.extract_articles_by_category(category_id)
            
            if articles_df.empty:
                logger.warning(f"Aucun article trouv√© pour la cat√©gorie {category_id}")
                return []
            
            results = []
            
            for _, article_row in articles_df.iterrows():
                logger.info(f"Analyse de l'article: {article_row['ArticleName']}")
                
                # Calcul de la promotion optimale avec impact inclus
                complete_analysis = self.calculate_optimal_promotion_percentage(article_row)
                results.append(complete_analysis)
            
            logger.info(f"Analyse termin√©e pour {len(results)} articles")
            return results
            
        except Exception as e:
            logger.error(f"Erreur lors de l'analyse de la cat√©gorie: {e}")
            return []
        finally:
            self.disconnect_database()
    
    def generate_summary_report(self, analysis_results: List[Dict]) -> str:
        """
        G√©n√®re un rapport de synth√®se
        
        Args:
            analysis_results (List[Dict]): R√©sultats d'analyse
            
        Returns:
            str: Rapport de synth√®se
        """
        if not analysis_results:
            return "Aucune donn√©e √† analyser"
        
        df = pd.DataFrame(analysis_results)
        
        # Statistiques g√©n√©rales
        avg_promotion = df['optimal_promotion_percentage'].mean()
        total_potential_revenue_change = df['revenue_change'].sum()
        total_potential_sales_change = df['sales_volume_change'].sum()
        
        # Articles par cat√©gorie de recommandation
        high_promotion = len(df[df['optimal_promotion_percentage'] > 30])
        medium_promotion = len(df[(df['optimal_promotion_percentage'] >= 15) & (df['optimal_promotion_percentage'] <= 30)])
        low_promotion = len(df[df['optimal_promotion_percentage'] < 15])
        
        report = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                            RAPPORT DE SYNTH√àSE SMARTPROMO AI                     ‚ïë
‚ïë                              {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}                              ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üìä STATISTIQUES G√âN√âRALES:
   ‚Ä¢ Nombre d'articles analys√©s: {len(analysis_results)}
   ‚Ä¢ Promotion moyenne recommand√©e: {avg_promotion:.1f}%
   ‚Ä¢ Impact total pr√©vu sur le revenu: {total_potential_revenue_change:,.2f} DT
   ‚Ä¢ Impact total pr√©vu sur les ventes: {total_potential_sales_change:,.0f} unit√©s

üìà R√âPARTITION DES PROMOTIONS:
   ‚Ä¢ Promotions √©lev√©es (>30%): {high_promotion} articles
   ‚Ä¢ Promotions moyennes (15-30%): {medium_promotion} articles  
   ‚Ä¢ Promotions faibles (<15%): {low_promotion} articles

üéØ TOP 5 DES OPPORTUNIT√âS:
"""
        
        # Top 5 des meilleures opportunit√©s
        top_opportunities = df.nlargest(5, 'revenue_change_percentage')
        for i, (_, row) in enumerate(top_opportunities.iterrows(), 1):
            report += f"   {i}. {row['article_name'][:30]:<30} | Promotion: {row['optimal_promotion_percentage']:>3}% | Impact: +{row['revenue_change_percentage']:>6.1f}%\n"
        
        report += f"\n‚ö†Ô∏è  ALERTES STOCK:\n"
        
        # Alertes stock critique
        critical_stock = df[df['current_stock'] <= self.thresholds['stock_critical']]
        if not critical_stock.empty:
            for _, row in critical_stock.iterrows():
                report += f"   ‚Ä¢ {row['article_name'][:40]:<40} | Stock: {row['current_stock']:>3} unit√©s (CRITIQUE)\n"
        else:
            report += "   ‚Ä¢ Aucune alerte stock critique\n"
        
        report += f"\nüìã RECOMMANDATIONS GLOBALES:\n"
        if total_potential_revenue_change > 0:
            report += f"   ‚úÖ Les promotions recommand√©es devraient augmenter le revenu global\n"
        else:
            report += f"   ‚ö†Ô∏è Attention: impact n√©gatif potentiel sur le revenu global\n"
            
        if high_promotion > len(analysis_results) * 0.3:
            report += f"   üì¶ Nombreux articles en surstock - campagne de d√©stockage recommand√©e\n"
            
        report += f"\n{'='*80}\n"
        
        return report


def main():
    """
    Fonction principale pour tester le mod√®le
    """
    # Configuration de la base de donn√©es
    CONNECTION_STRING = "Server=DESKTOP-S22JEMV\\SQLEXPRESS;Database=SmartPromoDb_v2026_Fresh;Trusted_Connection=True;"
    
    # Initialisation du mod√®le
    ai_model = SmartPromoAIModel(CONNECTION_STRING)
    
    print("ü§ñ SmartPromo AI Model - Calcul Intelligent des Promotions avec IA")
    print("=" * 70)
    
    try:
        # Tentative de chargement d'un mod√®le pr√©-entra√Æn√©
        if not ai_model.load_model():
            print("üìö Aucun mod√®le pr√©-entra√Æn√© trouv√©.")
            choice = input("Voulez-vous entra√Æner un nouveau mod√®le ? (o/n): ").strip().lower()
            
            if choice == 'o':
                print("\nüîÑ Entra√Ænement du mod√®le d'IA en cours...")
                
                # Demander le mode d'entra√Ænement
                mode_choice = input("Mode d'entra√Ænement: (1) Donn√©es r√©elles, (2) Donn√©es simul√©es, (3) Auto (d√©faut): ").strip()
                
                use_simulation = False
                if mode_choice == '2':
                    use_simulation = True
                    print("üìä Utilisation de donn√©es simul√©es pour l'entra√Ænement...")
                elif mode_choice == '1':
                    print("üóÑÔ∏è Tentative d'utilisation des donn√©es r√©elles...")
                else:
                    print("üîÑ Mode automatique: donn√©es r√©elles si possible, sinon simul√©es...")
                
                if ai_model.train_models(use_simulation=(mode_choice == '2')):
                    print("‚úÖ Mod√®le entra√Æn√© avec succ√®s !")
                    print("\nüìä M√©triques des mod√®les:")
                    for name, metrics in ai_model.model_metrics.items():
                        print(f"  {name}:")
                        print(f"    R¬≤ Score: {metrics['r2']:.3f}")
                        print(f"    RMSE: {metrics['rmse']:.3f}")
                        print(f"    MAE: {metrics['mae']:.3f}")
                else:
                    print("‚ùå √âchec de l'entra√Ænement. Utilisation de la m√©thode classique.")
            else:
                print("üìä Utilisation de la m√©thode de calcul classique (sans IA)")
        else:
            print("‚úÖ Mod√®le pr√©-entra√Æn√© charg√© avec succ√®s !")
            print("üìä M√©triques du mod√®le:")
            for name, metrics in ai_model.model_metrics.items():
                print(f"  {name}: R¬≤ = {metrics['r2']:.3f}, RMSE = {metrics['rmse']:.3f}")
        
        # Demande de la cat√©gorie √† analyser
        category_id = input("\nEntrez l'ID de la cat√©gorie √† analyser (ou 1 par d√©faut): ").strip()
        category_id = int(category_id) if category_id.isdigit() else 1
        
        print(f"\nüîç Analyse de la cat√©gorie {category_id} en cours...")
        if ai_model.is_trained:
            print("ü§ñ Utilisation de l'IA pour les pr√©dictions")
        else:
            print("üìä Utilisation de la m√©thode algorithmique classique")
        
        # Analyse de la cat√©gorie
        results = ai_model.analyze_category(category_id)
        
        if results:
            # Affichage des r√©sultats d√©taill√©s
            print(f"\nüìã R√âSULTATS D√âTAILL√âS:")
            print("-" * 120)
            
            for result in results:
                method_icon = "ü§ñ" if result.get('prediction_method') == 'ai' else "üìä"
                print(f"""
üè∑Ô∏è  Article: {result['article_name']}
   üí∞ Prix actuel: {result['current_price']:.2f} DT ‚Üí Prix promo: {result['discounted_price']:.2f} DT
   üìä Promotion recommand√©e: {result['optimal_promotion_percentage']}% {method_icon}
   üì¶ Stock actuel: {result['current_stock']} unit√©s
   
   üìà Scores d'analyse:
      ‚Ä¢ Rotation stock: {result['stock_score']:.2f}
      ‚Ä¢ √âlasticit√© prix: {result['elasticity_score']:.2f}  
      ‚Ä¢ Historique ventes: {result['sales_score']:.2f}
      ‚Ä¢ Historique promos: {result['promotion_score']:.2f}
      ‚Ä¢ Score final: {result['final_score']:.2f}
      ‚Ä¢ M√©thode: {result.get('prediction_method', 'classic')}
   
   üéØ Impact pr√©vu (30 jours):
      ‚Ä¢ Ventes: {result['current_monthly_sales_volume']:.0f} ‚Üí {result['predicted_monthly_sales_volume']:.0f} unit√©s ({result['sales_volume_change_percentage']:+.1f}%)
      ‚Ä¢ Revenu: {result['current_monthly_revenue']:.2f} ‚Üí {result['predicted_monthly_revenue']:.2f} DT ({result['revenue_change_percentage']:+.1f}%)
   
   üí° {result['recommendation']}
""")
                print("-" * 120)
            
            # Statistiques sur les m√©thodes utilis√©es
            ai_predictions = sum(1 for r in results if r.get('prediction_method') == 'ai')
            classic_predictions = len(results) - ai_predictions
            
            print(f"\nüìä STATISTIQUES DES PR√âDICTIONS:")
            print(f"   ü§ñ Pr√©dictions IA: {ai_predictions}")
            print(f"   üìä Pr√©dictions classiques: {classic_predictions}")
            
            # G√©n√©ration et affichage du rapport de synth√®se
            summary_report = ai_model.generate_summary_report(results)
            print(summary_report)
            
            # Sauvegarde des r√©sultats en JSON
            output_file = f"smartpromo_analysis_{category_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"üìÅ R√©sultats sauvegard√©s dans: {output_file}")
            
        else:
            print("‚ùå Aucun r√©sultat trouv√© pour cette cat√©gorie")
            
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Analyse interrompue par l'utilisateur")
    except Exception as e:
        print(f"‚ùå Erreur lors de l'ex√©cution: {e}")
        logger.error(f"Erreur principale: {e}")


if __name__ == "__main__":
    main()
